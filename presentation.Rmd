---
title: "A crash course on R for data analysis"
author: "Clemens Schmid"
date: "2022/11/18"
---

## Getting started

- Open RStudio
- Load the project with `File > Open Project...`
- Open the file `presentation.Rmd` in RStudio

# A crash course on R for data analysis

## TOC

- The working environment
- Loading data into tibbles
- Plotting data in tibbles
- Conditional queries on tibbles
- Transforming and manipulating tibbles
- Combining tibbles with join operations

# The working environment

## R, RStudio and the tidyverse

- R is a fully featured programming language, but it excels as an environment for (statistical) data analysis (https://www.r-project.org)

- RStudio is an integrated development environment (IDE) for R (and other languages): (https://www.rstudio.com/products/rstudio)

- The tidyverse is a collection of R packages with well-designed and consistent interfaces for the main steps of data analysis: loading, transforming and plotting data (https://www.tidyverse.org)
  - This introduction works with tidyverse ~v1.3.0
  - We will learn about `readr`, `tibble`, `ggplot2`, `dplyr`, `magrittr` and `tidyr`
  - `forcats` will be briefly mentioned
  - `purrr` and `stringr` are left out

# Loading data into tibbles

## Reading data with readr

- With R we usually operate on data in our computer's memory
- The tidyverse provides the package `readr` to read data from text files into the memory
- `readr` can read from our file system or the internet
- It provides functions to read data in almost any (text) format:

```{r eval=FALSE}
readr::read_csv()   # .csv files -> see data/penguins.csv
readr::read_tsv()   # .tsv files
readr::read_delim() # tabular files with an arbitrary separator
readr::read_fwf()   # fixed width files
readr::read_lines() # read linewise to parse yourself 
```

- `readr` automatically detects column types -- but you can also define them manually

## How does the interface of `read_csv` work?

- We can learn more about a function with `?`. To open a help file: `?readr::read_csv`
- `readr::read_csv` has many options to specify how to read a text file

```{r eval=FALSE}
read_csv(
  file,                      # The path to the file we want to read
  col_names = TRUE,          # Are there column names?
  col_types = NULL,          # Which types do the columns have? NULL -> auto
  locale = default_locale(), # How is information encoded in this file?
  na = c("", "NA"),          # Which values mean "no data"
  trim_ws = TRUE,            # Should superfluous white-spaces be removed?
  skip = 0,                  # Skip X lines at the beginning of the file
  n_max = Inf,               # Only read X lines
  skip_empty_rows = TRUE,    # Should empty lines be ignored? 
  comment = "",              # Should comment lines be ignored?
  name_repair = "unique",    # How should "broken" column names be fixed
  ...
)
```

## What does `readr` produce? The `tibble`!

```{r}
peng <- readr::read_csv("data/penguins.csv")
```

- The `tibble` is a "data frame", a tabular data structure with rows and columns
- Unlike a simple array, each column can have another data type

## How to look at a `tibble`?

```{r, eval=FALSE}
peng          # Typing the name of an object will print it to the console
str(peng)     # A structural overview of an object
summary(peng) # A human-readable summary of an object
View(peng)    # RStudio's interactive data browser
```



# Plotting data in `tibble`s

## `ggplot2` and the "grammar of graphics"

- `ggplot2` offers an unusual, but powerful and logical interface
- The following example describes a stacked bar chart

```{r}
library(ggplot2) # Loading a library to use its functions without ::
```

```{r eval=FALSE}
ggplot(          # Every plot starts with a call to the ggplot() function
  data = peng    # This function can also take the input tibble
) +              # The plot consists of functions linked with +
  geom_bar(        # "geoms" define the plot layers we want to draw
    mapping = aes( # The aes() function maps variables to visual properties
      x = island,    # publication_year -> x-axis
      fill = species # community_type -> fill color
    )
  )
```

- `geom_*`: data + geometry (bars) + statistical transformation (sum)
- `ggplot2` features many geoms: A good overview is provided by [this cheatsheet](https://www.rstudio.com/resources/cheatsheets)

## `scale`s control the behaviour of visual elements

- Another plot: Boxplots of sample age through time

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g))
```

- Let's assume we had some extreme outliers in this dataset

```{r}
peng_out <- peng
peng_out$body_mass_g[sample(1:nrow(peng_out), 10)] <- 15000 + 50000 * runif(10)
ggplot(peng_out) +
  geom_boxplot(aes(x = species, y = body_mass_g))
```

- This is not well readable, because the extreme outliers dictate the scale
- A 15kg penguin is a scary thought and we would probably remove these outliers, but let's assume they are valid observation we want to include in the plot

- To mitigate this issue we can change the **scale** of different visual elements - e.g. the y-axis

```{r}
ggplot(peng_out) +
  geom_boxplot(aes(x = species, y = body_mass_g)) +
  scale_y_log10()
```

- The log-scale improves readability

## Other `scale`s

- (Fill) color is a visual element of the plot and its scaling can be adjusted

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g, fill = species)) +
  scale_y_log10() +
  scale_fill_viridis_d(option = "C")
```

## Defining plot matrices via `facet`s

- Splitting up the plot by categories into **facets** is another way to visualize more variables at once

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g)) +
  facet_wrap(~year)
```

- Unfortunately the x-axis became unreadable

## Setting purely aesthetic settings with `theme`

- Aesthetic changes like this can be applied as part of the `theme`

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g)) +
  facet_wrap(~year) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```

## Exercise 1

1. Look at the `mtcars` dataset and read up on the meaning of its variables

```{r}

```

2. Visualize the relationship between *Gross horsepower* and *1/4 mile time*

```{r}

```

3. Integrate the *Number of cylinders* into your plot

```{r}

```















## Possible solutions 1

1. Look at the `mtcars` dataset and read up on the meaning of its variables

```{r, eval=FALSE}
?mtcars
```

2. Visualize the relationship between *Gross horsepower (hp)* and *1/4 mile time (qsec)*

```{r, eval=FALSE}
ggplot(mtcars) + geom_point(aes(x = hp, y = qsec))
```

3. Integrate the *Number of cylinders* into your plot

```{r, eval=FALSE}
ggplot(mtcars) + geom_point(aes(x = hp, y = qsec, color = as.factor(cyl)))
```



# Conditional queries on tibbles

## Selecting columns and filtering rows with `select` and `filter`

- The `dplyr` package includes powerful functions to subset data in tibbles based on conditions
- `dplyr::select` allows to select columns

```{r}
dplyr::select(peng, id, flipper_length_mm)   # reduce to two columns
dplyr::select(peng, -island, -flipper_length_mm) # remove two columns 
```

- `dplyr::filter` allows for conditional filtering of rows

```{r}
dplyr::filter(peng, year == 2007) # penguins measured in 2007
dplyr::filter(peng, year == 2007 |
                    year == 2009) # penguins measured in 2007 OR 2009
dplyr::filter(peng, year %in% c(2007, 2009)) # match operator: %in%
dplyr::filter(peng, species == "Adelie" & 
                    body_mass_g >= 4000) # Adelie penguins heavier than 4kg
```

## Chaining functions together with the pipe `%>%`

- The pipe `%>%` in the `magrittr` package is a clever infix operator to chain data and operations

```{r}
library(magrittr)
peng %>% dplyr::filter(year == 2007)
```

- It forwards the LHS as the first argument of the function appearing on the RHS
- That allows for sequences of functions ("tidyverse style")

```{r}
peng %>%
  dplyr::select(id, species, body_mass_g) %>%
  dplyr::filter(species == "Adelie" & body_mass_g >= 4000) %>%
  nrow() # count the rows
```

- `magrittr` also offers some more operators, among which the extraction `%$%` is particularly useful

```{r}
peng %>%
  dplyr::filter(island == "Biscoe") %$%
  species %>% # extract the sample_age column as a vector
  unique()    # get the unique elements of said vector
```

## Summary statistics in `base` R

- Summarising and counting data is indispensable and R offers all operations you would expect in its `base` package

```{r}
chinstraps <- peng %>% dplyr::filter(species == "Chinstrap")

nrow(chinstraps)               # number of rows in a tibble
length(chinstraps$species)     # length/size of a vector
unique(chinstraps$species)     # unique elements of a vector

min(chinstraps$body_mass_g)    # minimum
max(chinstraps$body_mass_g)    # maximum

mean(chinstraps$body_mass_g)   # mean
median(chinstraps$body_mass_g) # median

var(chinstraps$body_mass_g)    # variance
sd(chinstraps$body_mass_g)     # standard deviation
quantile(chinstraps$body_mass_g, probs = 0.75) # sample quantiles for the given probs
```

- many of these functions can ignore missing values with an option `na.rm = TRUE`

## Group-wise summaries with `group_by` and `summarise`

- These summary statistics are particular useful when applied to conditional subsets of a dataset
- `dplyr` allows such summary operations with a combination of `group_by` and `summarise`

```{r}
peng %>%
  dplyr::group_by(species) %>% # group the tibble by the material column
  dplyr::summarise(
    min_age = min(body_mass_g),       # a new column: min weight for each group
    median_age = median(body_mass_g), # a new column: median weight for each group
    max_age = max(body_mass_g)        # a new column: max weight for each group
  )
```

- grouping can be applied across multiple columns

```{r}
peng %>%
  dplyr::group_by(species, year) %>% # group by species and year
  dplyr::summarise(
    n = dplyr::n(),  # a new column: number of penguins for each group
    .groups = "drop" # drop the grouping after this summary operation
  )
```

## Sorting and slicing tibbles with `arrange` and `slice`

- `dplyr` allows to `arrange` tibbles by one or multiple columns

```{r}
peng %>% dplyr::arrange(sex)              # sort by sex
peng %>% dplyr::arrange(sex, body_mass_g) # ... and weight
peng %>% dplyr::arrange(dplyr::desc(body_mass_g)) # sort descendingly on weight
```

- Sorting also works within groups and can be paired with `slice` to extract extreme values per group

```{r}
peng %>%
  dplyr::group_by(species) %>%                 # group by species
  dplyr::arrange(dplyr::desc(body_mass_g)) %>% # sort by weight within (!) groups
  dplyr::slice_head(n = 3) %>%                 # keep the first three samples per group
  dplyr::ungroup()                             # remove the still lingering grouping
```

- Slicing is also the relevant operation to take random samples from the observations in a tibble

```{r}
peng %>% dplyr::slice_sample(n = 10)
```



## Exercise 2

1. Determine the number of cars with four *forward gears* (`gear`) in the `mtcars` dataset

```{r}

```

2. Determine the mean *1/4 mile time* (`qsec`) per *Number of cylinders* (`cyl`) group

```{r}

```

3. Identify the least efficient cars for both *transmission types* (`am`)

```{r}

```















## Possible solutions 2

1. Determine the number of cars with four *forward gears* (`gear`) in the `mtcars` dataset

```{r, eval=FALSE}
mtcars %>% dplyr::filter(gear == 4) %>% nrow()
```

2. Determine the mean *1/4 mile time* (`qsec`) per *Number of cylinders* (`cyl`) group

```{r, eval=FALSE}
mtcars %>% dplyr::group_by(cyl) %>% dplyr::summarise(qsec_mean = mean(qsec))
```

3. Identify the least efficient cars for both *transmission types* (`am`)

```{r, eval=FALSE}
#mtcars3 <- tibble::rownames_to_column(mtcars, var = "car") %>% tibble::as_tibble()
mtcars %>% dplyr::group_by(am) %>% dplyr::arrange(mpg) %>% dplyr::slice_head()
```



# Transforming and manipulating tibbles

## Renaming and reordering columns and values with `rename`, `relocate` and `recode`

- Columns in tibbles can be renamed with `dplyr::rename` and reordered with `dplyr::relocate`

```{r}
peng %>% dplyr::rename(penguin_name = id) # rename a column
peng %>% dplyr::relocate(year, .before = species) # reorder columns
```

- Values in columns can be changed with `dplyr::recode`

```{r}
peng$island %>% dplyr::recode(Torgersen = "My favourite Island")
```

- R supports explicitly ordinal data with `factor`s, which can be reordered as well
- `factor`s can be handled more easily with the `forcats` package

```{r, fig.show='hide'}
ggplot(peng) + geom_bar(aes(x = species)) # bars are alphabetically ordered
peng2 <- peng
peng2$species_ordered <- forcats::fct_reorder(peng2$species, peng2$species, length)
# fct_reorder: reorder the input factor by a summary statistic on an other vector
ggplot(peng2) + geom_bar(aes(x = species_ordered)) # bars are ordered by size
```

## Adding columns to tibbles with `mutate` and `transmute`

- A common application of data manipulation is adding derived columns. `dplyr` offers that with `mutate`

```{r}
peng %>% 
  dplyr::mutate(                    # add a column that
    body_mass_kg = body_mass_g/1000 # manipulates an existing column
  )
```

- `dplyr::transmute` removes all columns but the newly created ones

```{r}
peng %>% 
  dplyr::transmute(
    id = paste("Penguin Nr.", id), # overwrite this column
    flipper_length_mm              # select this column
)
```

- `dplyr::mutate` can also be combined with `dplyr::group_by` (instead of `dplyr::summarise`)

```{r}
peng %>%
  dplyr::group_by(species, sex, year) %>%
  dplyr::mutate( # mutate does not collapse rows, unlike summarise
    mean_weight = mean(body_mass_g, na.rm = T)
  ) %>%
  dplyr::arrange(body_mass_g)
```

- `tibble::add_column` behaves as `dplyr::mutate`, but gives more control over column position

```{r}
peng %>% tibble::add_column(
  flipper_length_cm = .$flipper_length_mm/10, # not the . representing the LHS of the pipe
  .after = "flipper_length_mm"
)
```

## Conditional operations with `ifelse` and `case_when`

- `ifelse` allows to implement conditional `mutate` operations, that consider information from other columns, but that gets cumbersome easily

```{r}
peng %>% dplyr::mutate(
  weight = ifelse(
    test = body_mass_g >= 4200, # is weight below or above mean weight?
    yes = "above mean",
    no = "below mean"
  )
)
```

- `dplyr::case_when` is more readable and scales much better for this application

```{r}
peng %>% dplyr::mutate(
  weight = dplyr::case_when(
    body_mass_g >= 4200 ~ "above mean", # the number of conditions is arbitrary
    body_mass_g < 4200  ~ "below mean",
    TRUE                ~ "unknown"     # TRUE catches all remaining cases
  )
)
```

## Long and wide data formats

- For different applications or to simplify certain analysis or plotting operations data often has to be transformed from a **wide** to a **long** format or vice versa

![](figures/pivot_longer_wider.png){height=150px}

- A table in **wide** format has N key columns and N value columns
- A table in **long** format has N key columns, one descriptor column and one value column

## A wide dataset

```{r}
carsales <- tibble::tribble(
  ~brand, ~`2014`, ~`2015`, ~`2016`, ~`2017`,
  "BMW",  20,      25,      30,      45,
  "VW",   67,      40,     120,      55
)
```

- Wide format becomes a problem, when the columns are semantically identical. This dataset is in wide format and we can not easily plot it
- We generally prefer data in long format, although it is more verbose with more duplication. "Long" format data is more "tidy"

## Making a wide dataset long with `pivot_longer`

```{r}
carsales_long <- carsales %>% tidyr::pivot_longer(
  cols = tidyselect::num_range("", range = 2014:2017), # set of columns to transform
  names_to = "year",            # the name of the descriptor column we want
  names_transform = as.integer, # a transformation function to apply to the names
  values_to = "sales"           # the name of the value column we want
)
```

## Making a long dataset wide with `pivot_wider`

```{r}
carsales_wide <- carsales_long %>% tidyr::pivot_wider(
  id_cols = "brand",  # the set of id columns that should not be changed
  names_from = year,  # the descriptor column with the names of the new columns
  values_from = sales # the value column from which the values should be extracted
)
```

- Applications of wide datasets are adjacency matrices to represent graphs, covariance matrices or other pairwise statistics
- When data gets big, then wide formats can be significantly more efficient (e.g. for spatial data)



## Exercise 3

1. Move the column `gear` to the first position of the mtcars dataset

```{r}

```

2. Make a new dataset `mtcars2` with the column `mpg` and an additional column `am_v`, which encodes the *transmission type* (`am`) as either `"manual"` or `"automatic"`

```{r}

```

3. Count the number of cars per *transmission type* (`am_v`) and *number of gears* (`gear`). Then transform the result to a wide format, with one column per *transmission type*.

```{r}

```















## Possible solutions 3

1. Move the column `gear` to the first position of the mtcars dataset

```{r, eval=FALSE}
mtcars %>% dplyr::relocate(gear, .before = mpg)
```

2. Make a new dataset `mtcars2` with the column `gear` and an additional column `am_v`, which encodes the *transmission type* (`am`) as either `"manual"` or `"automatic"`

```{r, eval=FALSE}
mtcars2 <- mtcars %>% dplyr::mutate(
  gear, am_v = dplyr::case_when(am == 0 ~ "automatic", am == 1 ~ "manual")
)
```

3. Count the number of cars in `mtcars2` per *transmission type* (`am_v`) and *number of gears* (`gear`). Then transform the result to a wide format, with one column per *transmission type*.

```{r, eval=FALSE}
mtcars2 %>% dplyr::group_by(am_v, gear) %>% dplyr::tally() %>%
  tidyr::pivot_wider(names_from = am_v, values_from = n)
```



# Combining tibbles with join operations

## Types of joins

Joins combine two datasets x and y based on key columns

- Mutating joins add columns from one dataset to the other
  - Left join: Take observations from x and add fitting information from y
  - Right join: Take observations from y and add fitting information from x
  - Inner join: Join the overlapping observations from x and y
  - Full join: Join all observations from x and y, even if information is missing
- Filtering joins remove observations from x based on their presence in y
  - Semi join: Keep every observation in x that is in y
  - Anti join: Keep every observation in x that is not in y

## A second dataset

- Contains additional variables for a subset of penguins
- Both datasets feature 300 penguins, but only with a partial overlap of individuals

```{r echo=FALSE}
bills <- readr::read_csv("data/penguin_bills_2009.csv")
print(bills, n = 5)
```

## Left join

Take observations from x and add fitting information from y

![](figures/left_join.png){height=150px}

```{r}
dplyr::left_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"  # the key column by which to join
)
```

- Left joins are the most common join operation: Add information from y to the main dataset x

## Right join

Take observations from y and add fitting information from x

![](figures/right_join.png){height=150px}

```{r}
dplyr::right_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
) %>% dplyr::arrange(id)
```

- Right joins are almost identical to left joins -- only x and y have reversed roles

## Inner join

Join the overlapping observations from x and y

![](figures/inner_join.png){height=150px}

```{r}
dplyr::inner_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
)
```

- Inner joins are a fast and easy way to check, to which degree two dataset overlap

## Full join

Join all observations from x and y, even if information is missing

![](figures/full_join.png){height=150px}

```{r}
dplyr::full_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
)
```

- Full joins allow to preserve every bit of information

## Semi join

Keep every observation in x that is in y

![](figures/semi_join.png){height=150px}

```{r}
dplyr::semi_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
)
```

- Semi joins are underused operations to filter datasets

## Anti join

Keep every observation in x that is not in y

![](figures/anti_join.png){height=150px}

```{r}
dplyr::anti_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
)
```

- Anti joins allow to quickly specify incomplete datasets and missing information



## Exercise 4

Consider the following additional dataset:

```{r}
gear_opinions <- tibble::tibble(gear = c(3, 5), opinion = c("boring", "wow"))
```

1. Add my opinions about gears to the `mtcars` dataset

```{r}

```

2. Remove all cars from the dataset for which I don't have an opinion

```{r}

```















## Possible Solutions 4

1. Add my opinions about gears to the `mtcars` dataset

```{r, eval=FALSE}
dplyr::left_join(mtcars, gear_opinions, by = "gear")
```

2. Remove all cars from the dataset for which I don't have an opinion

```{r, eval=FALSE}
dplyr::anti_join(mtcars, gear_opinions, by = "gear")
```
